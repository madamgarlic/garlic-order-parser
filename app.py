import streamlit as st
import pandas as pd
import io
from datetime import datetime
import re
from typing import Dict, List, Tuple
from dataclasses import dataclass, field
from collections import defaultdict

# íŒŒì‹± ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤
@dataclass
class ParsedProduct:
    original_text: str
    product_name: str
    weight: str
    unit: str
    is_bulk: bool
    category: str

# íŒ¨í‚¹ ì•„ì´í…œ ë°ì´í„° í´ë˜ìŠ¤
@dataclass
class PackingItem:
    product_name: str
    category: str
    unit_weight: float
    unit: str
    quantity: int
    total_weight: float
    is_bulk: bool
    order_files: List[str] = field(default_factory=list)

@dataclass
class PackingSummary:
    total_items: int
    total_weight: float
    bulk_items: int
    bulk_weight: float
    regular_items: int
    regular_weight: float
    categories: Dict[str, int]
    total_orders: int
    combined_delivery_count: int
    unique_delivery_locations: int

@dataclass
class DeliveryInfo:
    recipient_name: str
    address: str
    order_count: int
    order_files: List[str] = field(default_factory=list)

class GarlicOrderParser:
    """ë§ˆëŠ˜ ì£¼ë¬¸ì„œ íŒŒì‹± ì—”ì§„"""
    
    def __init__(self):
        self.parsing_rules = {
            'primary_target_columns': ['ì˜µì…˜ì •ë³´', 'ì˜µì…˜'],
            'fallback_columns': ['ìƒí’ˆëª…', 'ì œí’ˆëª…', 'í’ˆëª©ëª…'],
            'bracket_exceptions': ['íŠ¹', 'ëŒ€', 'ì¤‘', 'ì†Œ', 'ëŒ€ ê¼­ì§€ì œê±°'],
            'bulk_threshold': 5.0,
        }
    
    def find_target_columns(self, df: pd.DataFrame) -> Tuple[str, str]:
        """íƒ€ê²Ÿ ì»¬ëŸ¼ë“¤ ì°¾ê¸°"""
        primary_col = None
        fallback_col = None
        
        # ì£¼ìš” íƒ€ê²Ÿ ì»¬ëŸ¼ ì°¾ê¸°
        for col in df.columns:
            col_str = str(col).strip()
            for target in self.parsing_rules['primary_target_columns']:
                if target == col_str or target in col_str:
                    primary_col = col
                    break
            if primary_col:
                break
        
        # ë³´ì¡° íƒ€ê²Ÿ ì»¬ëŸ¼ ì°¾ê¸°
        for col in df.columns:
            col_str = str(col).strip()
            for target in self.parsing_rules['fallback_columns']:
                if target == col_str or target in col_str:
                    fallback_col = col
                    break
            if fallback_col:
                break
        
        if not primary_col and not fallback_col:
            raise ValueError("íŒŒì‹±í•  ìˆ˜ ìˆëŠ” ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return primary_col, fallback_col
    
    def get_parsing_text(self, row: pd.Series, primary_col: str, fallback_col: str) -> Tuple[str, str]:
        """íŒŒì‹±í•  í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        source_column = ""
        text_to_parse = ""
        
        # ì£¼ìš” ì»¬ëŸ¼ì—ì„œ ë¨¼ì € í™•ì¸
        if primary_col and primary_col in row.index:
            primary_text = row[primary_col]
            if pd.notna(primary_text) and str(primary_text).strip():
                text_to_parse = str(primary_text).strip()
                source_column = primary_col
                return text_to_parse, source_column
        
        # ë³´ì¡° ì»¬ëŸ¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if fallback_col and fallback_col in row.index:
            fallback_text = row[fallback_col]
            if pd.notna(fallback_text) and str(fallback_text).strip():
                text_to_parse = str(fallback_text).strip()
                source_column = fallback_col
                return text_to_parse, source_column
        
        return "", ""
    
    def clean_text(self, text: str) -> str:
        """ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ì œ"""
        if pd.isna(text):
            return ""
        
        text = str(text).strip()
        
        # ë¬´ì¡°ê±´ ì‚­ì œí•  ë‹¨ì–´ë“¤ ì œê±°
        words_to_remove = ['[ë§ˆëŠ˜ê·€ì‹ ]', 'ê²½ë¶', 'ì˜ì„±', 'êµ­ë‚´ì‚°', 'ë§ˆëŠ˜ê·€ì‹ ', 'êµ­ì‚°']
        for word in words_to_remove:
            text = re.sub(re.escape(word), '', text, flags=re.IGNORECASE)
        
        # ê¸°ì¡´ ì—…ì†Œìš© í‘œê¸° ì‚­ì œ
        text = re.sub(r'ì—…ì†Œìš©', '', text, flags=re.IGNORECASE)
        text = re.sub(r'\(ì—…ì†Œìš©\)', '', text, flags=re.IGNORECASE)
        text = re.sub(r'\(\s*ì—…ì†Œìš©\s*\)', '', text, flags=re.IGNORECASE)
        
        # ê´„í˜¸ ì²˜ë¦¬ (ìˆ˜ì‹ ì²´í¬ ì „ì— ë¨¼ì € ì²˜ë¦¬)
        text = self._process_brackets(text)
        
        # í•˜ì´í”ˆ(-) ì²˜ë¦¬ ì¶”ê°€ - í•˜ì´í”ˆ í¬í•¨ ë’¤ì˜ ëª¨ë“  ì •ë³´ ì‚­ì œ
        text = self._process_hyphen(text)
        
        # ì†ì§ˆëœ ë§ˆëŠ˜ì«‘ ê´€ë ¨ í‘œí˜„ë“¤ì„ "ë§ˆëŠ˜ì«‘"ìœ¼ë¡œ ëŒ€ì²´ ë° ì¤‘ë³µ ì œê±°
        garlic_stem_patterns = [
            r'ì†ì§ˆëœ\s*ë§ˆëŠ˜ì«‘',
            r'\(\s*ì†ì§ˆëœ\s*ë§ˆëŠ˜ì«‘\s*\)',
            r'ì†ì§ˆë§ˆëŠ˜ì«‘',
            r'\(\s*ì†ì§ˆë§ˆëŠ˜ì«‘\s*\)'
        ]
        
        for pattern in garlic_stem_patterns:
            text = re.sub(pattern, 'ë§ˆëŠ˜ì«‘', text, flags=re.IGNORECASE)
        
        # ë§ˆëŠ˜ì«‘ ì¤‘ë³µ ì œê±°
        if 'ë§ˆëŠ˜ì«‘' in text.lower():
            weight_matches = re.findall(r'\d+(?:\.\d+)?\s*(?:KG|kg|í‚¤ë¡œ|G|g|ê·¸ë¨)', text, re.IGNORECASE)
            weight_part = weight_matches[0] if weight_matches else ""
            
            if weight_part:
                text = f"ë§ˆëŠ˜ì«‘ {weight_part}"
            else:
                text = "ë§ˆëŠ˜ì«‘"
        
        # ì½œë¡ /ìŠ¬ë˜ì‹œ ì²˜ë¦¬
        text = self._process_delimiters(text)
        
        # ìˆ˜ì‹ í•©ì‚° ì²˜ë¦¬ (ë‹¨ìœ„ê°€ ê°™ì€ ê²½ìš°ë§Œ)
        text = self._process_math_expressions(text)
        
        # ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±° (ìˆ˜ì‹ ì²˜ë¦¬ í›„)
        text = re.sub(r'[,]+', ' ', text)
        
        # ì¤‘ë³µ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _process_brackets(self, text: str) -> str:
        """ê´„í˜¸ ì²˜ë¦¬ ë¡œì§"""
        bracket_pattern = r'\(([^)]+)\)'
        
        def replace_bracket(match):
            content = match.group(1).strip()
            if content in self.parsing_rules['bracket_exceptions']:
                return f" {content} "
            return ' '
        
        result = re.sub(bracket_pattern, replace_bracket, text)
        return re.sub(r'\s+', ' ', result).strip()
    
    def _process_hyphen(self, text: str) -> str:
        """í•˜ì´í”ˆ(-) ì²˜ë¦¬ ë¡œì§"""
        if '-' in text:
            text = text.split('-')[0].strip()
        return text
    
    def _process_math_expressions(self, text: str) -> str:
        """ìˆ˜ì‹ í•©ì‚° ì²˜ë¦¬ (ë‹¨ìœ„ê°€ ê°™ì€ ê²½ìš°ë§Œ) - ì™„ì „ ë³µì›"""
        
        # ë¬´ê²Œ ë‹¨ìœ„ ìˆ˜ì‹ (KG, kg, í‚¤ë¡œ, í‚¤, k)
        kg_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:KG|kg|í‚¤ë¡œ|í‚¤|k)\s*[+xÃ—]\s*(\d+(?:\.\d+)?)\s*(?:KG|kg|í‚¤ë¡œ|í‚¤|k)',
        ]
        
        for pattern in kg_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                num1, num2 = float(match.group(1)), float(match.group(2))
                result = num1 + num2
                if result == int(result):
                    result_str = f"{int(result)}KG"
                else:
                    result_str = f"{result}KG"
                text = re.sub(pattern, result_str, text, flags=re.IGNORECASE)
                break
        
        # ê·¸ë¨ ë‹¨ìœ„ ìˆ˜ì‹ (G, g, ê·¸ë¨)
        g_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:G|g|ê·¸ë¨)\s*[+xÃ—]\s*(\d+(?:\.\d+)?)\s*(?:G|g|ê·¸ë¨)',
        ]
        
        for pattern in g_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                num1, num2 = float(match.group(1)), float(match.group(2))
                result = num1 + num2
                if result == int(result):
                    result_str = f"{int(result)}G"
                else:
                    result_str = f"{result}G"
                text = re.sub(pattern, result_str, text, flags=re.IGNORECASE)
                break
        
        # íŒ© ë‹¨ìœ„ ìˆ˜ì‹
        pack_pattern = r'(\d+)\s*íŒ©\s*[+xÃ—]\s*(\d+)\s*íŒ©'
        pack_match = re.search(pack_pattern, text)
        if pack_match:
            num1, num2 = int(pack_match.group(1)), int(pack_match.group(2))
            result = num1 + num2
            text = re.sub(pack_pattern, f'{result}íŒ©', text)
        
        # ê°œ ë‹¨ìœ„ ìˆ˜ì‹
        ea_pattern = r'(\d+)\s*ê°œ\s*[+xÃ—]\s*(\d+)\s*ê°œ'
        ea_match = re.search(ea_pattern, text)
        if ea_match:
            num1, num2 = int(ea_match.group(1)), int(ea_match.group(2))
            result = num1 + num2
            text = re.sub(ea_pattern, f'{result}ê°œ', text)
        
        # í¬ ë‹¨ìœ„ ìˆ˜ì‹
        po_pattern = r'(\d+)\s*í¬\s*[+xÃ—]\s*(\d+)\s*í¬'
        po_match = re.search(po_pattern, text)
        if po_match:
            num1, num2 = int(po_match.group(1)), int(po_match.group(2))
            result = num1 + num2
            text = re.sub(po_pattern, f'{result}í¬', text)
        
        # ë´‰ ë‹¨ìœ„ ìˆ˜ì‹
        bag_pattern = r'(\d+)\s*ë´‰\s*[+xÃ—]\s*(\d+)\s*ë´‰'
        bag_match = re.search(bag_pattern, text)
        if bag_match:
            num1, num2 = int(bag_match.group(1)), int(bag_match.group(2))
            result = num1 + num2
            text = re.sub(bag_pattern, f'{result}ë´‰', text)
        
        # í†µ ë‹¨ìœ„ ìˆ˜ì‹
        container_pattern = r'(\d+)\s*í†µ\s*[+xÃ—]\s*(\d+)\s*í†µ'
        container_match = re.search(container_pattern, text)
        if container_match:
            num1, num2 = int(container_match.group(1)), int(container_match.group(2))
            result = num1 + num2
            text = re.sub(container_pattern, f'{result}í†µ', text)
        
        return text
    
    def _process_delimiters(self, text: str) -> str:
        """ì½œë¡ /ìŠ¬ë˜ì‹œ ì²˜ë¦¬"""
        if ':' in text:
            text = text.split(':')[-1].strip()
        
        if '/' in text:
            text = text.split('/')[0].strip()
        
        return text
    
    def extract_weight_info(self, text: str) -> Tuple[str, str, str]:
        """ë¬´ê²Œ ì •ë³´ ì¶”ì¶œ - ì™„ì „ ë³µì›"""
        weight_patterns = [
            r'(\d+(?:\.\d+)?)\s*í‚¤ë¡œ\s*(?:ê·¸ë¨)?',
            r'(\d+(?:\.\d+)?)\s*(KG|kg)',
            r'(\d+(?:\.\d+)?)\s*(G|g|ê·¸ë¨)',
            r'(\d+(?:\.\d+)?)\s*(?:í‚¤|k)',
        ]
        
        weight_value = ""
        unit = ""
        
        for i, pattern in enumerate(weight_patterns):
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                weight_num = float(match.group(1))
                
                if i == 0:  # í‚¤ë¡œ
                    weight_value = str(weight_num)
                    unit = 'KG'
                elif i == 1:  # KG/kg
                    weight_value = str(weight_num)
                    unit = 'KG'
                elif i == 2:  # G/g/ê·¸ë¨
                    if weight_num >= 1000:
                        weight_value = str(weight_num / 1000)
                        unit = 'KG'
                    else:
                        weight_value = str(weight_num / 1000)
                        unit = 'KG'
                elif i == 3:  # í‚¤/k
                    weight_value = str(weight_num)
                    unit = 'KG'
                
                break
        
        return text, weight_value, unit
    
    def classify_product(self, text: str) -> str:
        """ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        text_lower = text.lower()
        
        category_priority = [
            ('ë§ˆëŠ˜ì«‘', ['ë§ˆëŠ˜ì«‘', 'ì«‘', 'ë§ˆëŠ˜ì¢…', 'ë§ˆëŠ˜ì¤„ê¸°']),
            ('ë‹¤ì§„ë§ˆëŠ˜', ['ë‹¤ì§„ë§ˆëŠ˜', 'ë§ˆëŠ˜ë‹¤ì§„', 'ë‹¤ì§„', 'ìœ¼ê¹¬ë§ˆëŠ˜', 'ê°ˆì€ë§ˆëŠ˜']),
            ('ê¹ë§ˆëŠ˜', ['ê¹”ë§ˆëŠ˜', 'ê¹ë§ˆëŠ˜', 'ë§ˆëŠ˜ê¹ê²ƒ', 'ë²—ê¸´ë§ˆëŠ˜', 'ê»ì§ˆë²—ê¸´ë§ˆëŠ˜']),
            ('ë‹­ë°œ', ['ë‹­ë°œ'])
        ]
        
        for category, keywords in category_priority:
            if any(keyword in text_lower for keyword in keywords):
                return category
        
        if 'ë§ˆëŠ˜' in text_lower:
            return "ë§ˆëŠ˜ê¸°íƒ€"
        
        return "ê¸°íƒ€"
    
    def apply_business_rules(self, parsed: ParsedProduct) -> ParsedProduct:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ì ìš©"""
        # ê¹ë§ˆëŠ˜/ë‹¤ì§„ë§ˆëŠ˜ì—ì„œ ìœ¡ìª½ì´ ì—†ìœ¼ë©´ ëŒ€ì„œ ìë™ ì¶”ê°€
        if parsed.category in ['ê¹ë§ˆëŠ˜', 'ë‹¤ì§„ë§ˆëŠ˜']:
            product_lower = parsed.product_name.lower()
            if 'ìœ¡ìª½' not in product_lower:
                if 'ëŒ€ì„œ' not in product_lower:
                    parsed.product_name = f"ëŒ€ì„œ {parsed.product_name}"
        
        # ë‹¤ì§„ë§ˆëŠ˜ì—ì„œ ê¼­ì§€í¬í•¨ ì²˜ë¦¬
        if parsed.category == 'ë‹¤ì§„ë§ˆëŠ˜':
            product_lower = parsed.product_name.lower()
            if 'ê¼­ì§€í¬í•¨' in product_lower:
                parsed.product_name = re.sub(
                    r'ê¼­ì§€í¬í•¨', 
                    '* ê¼­ ì§€ í¬ í•¨ *', 
                    parsed.product_name, 
                    flags=re.IGNORECASE
                )
        
        # ì—…ì†Œìš© íƒœê·¸ ì²˜ë¦¬ (5KG ì´ìƒ, ê¹ë§ˆëŠ˜/ë‹¤ì§„ë§ˆëŠ˜ë§Œ ëŒ€ìƒ)
        if parsed.category in ['ê¹ë§ˆëŠ˜', 'ë‹¤ì§„ë§ˆëŠ˜'] and parsed.weight:
            try:
                weight_val = float(parsed.weight)
                if weight_val >= self.parsing_rules['bulk_threshold']:
                    if 'ì—…ì†Œìš©' not in parsed.product_name and '** ì—… ì†Œ ìš© **' not in parsed.product_name:
                        parsed.product_name = f"** ì—… ì†Œ ìš© ** {parsed.product_name}"
                        parsed.is_bulk = True
            except (ValueError, TypeError):
                pass
        
        # ìƒí’ˆëª… ì •ë¦¬
        parsed.product_name = re.sub(r'\s+', ' ', parsed.product_name).strip()
        
        return parsed
    
    def parse_single_item(self, text: str) -> Tuple[ParsedProduct, List[str]]:
        """ë‹¨ì¼ í•­ëª© íŒŒì‹±"""
        original_text = text
        warnings = []
        
        try:
            # ê¸°ë³¸ ì •ì œ
            cleaned_text = self.clean_text(text)
            
            # ë¬´ê²Œ ì •ë³´ ì¶”ì¶œ (ì›ë³¸ í…ìŠ¤íŠ¸ ë³´ì¡´)
            _, weight, unit = self.extract_weight_info(cleaned_text)
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            category = self.classify_product(cleaned_text)
            
            # ParsedProduct ê°ì²´ ìƒì„±
            parsed = ParsedProduct(
                original_text=original_text,
                product_name=cleaned_text,
                weight=weight,
                unit=unit,
                is_bulk=False,
                category=category
            )
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ì ìš©
            parsed = self.apply_business_rules(parsed)
            
            return parsed, warnings
            
        except Exception as e:
            warnings.append(f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            
            return ParsedProduct(
                original_text=original_text,
                product_name=text,
                weight="",
                unit="",
                is_bulk=False,
                category="ì˜¤ë¥˜"
            ), warnings
    
    def parse_dataframe(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict]:
        """ë°ì´í„°í”„ë ˆì„ ì „ì²´ íŒŒì‹±"""
        result_df = df.copy()
        parsing_log = {
            'total_rows': len(df),
            'success_count': 0,
            'warning_count': 0,
            'error_count': 0,
            'warnings': [],
            'errors': [],
            'primary_column': None,
            'fallback_column': None,
            'source_stats': {'primary': 0, 'fallback': 0, 'empty': 0}
        }
        
        try:
            # íƒ€ê²Ÿ ì»¬ëŸ¼ë“¤ ì°¾ê¸°
            primary_col, fallback_col = self.find_target_columns(df)
            parsing_log['primary_column'] = primary_col
            parsing_log['fallback_column'] = fallback_col
            
            # ê²°ê³¼ ì»¬ëŸ¼ëª… ê²°ì •
            result_col_base = primary_col if primary_col else fallback_col
            
            # íŒŒì‹± ê²°ê³¼ ì €ì¥í•  ìƒˆ ì»¬ëŸ¼ë“¤
            result_df[f'{result_col_base}_parsed'] = ""
            result_df[f'{result_col_base}_weight'] = ""
            result_df[f'{result_col_base}_unit'] = ""
            result_df[f'{result_col_base}_category'] = ""
            result_df[f'{result_col_base}_is_bulk'] = False
            result_df[f'{result_col_base}_source'] = ""
            
            # ê° í–‰ íŒŒì‹±
            for idx, row in df.iterrows():
                # íŒŒì‹±í•  í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                text_to_parse, source_column = self.get_parsing_text(row, primary_col, fallback_col)
                
                if not text_to_parse:
                    parsing_log['source_stats']['empty'] += 1
                    continue
                
                # ì†ŒìŠ¤ í†µê³„ ì—…ë°ì´íŠ¸
                if source_column == primary_col:
                    parsing_log['source_stats']['primary'] += 1
                elif source_column == fallback_col:
                    parsing_log['source_stats']['fallback'] += 1
                
                # íŒŒì‹± ì‹¤í–‰
                parsed, warnings = self.parse_single_item(text_to_parse)
                
                # ê²°ê³¼ ì €ì¥
                result_df.loc[idx, f'{result_col_base}_parsed'] = parsed.product_name
                result_df.loc[idx, f'{result_col_base}_weight'] = parsed.weight
                result_df.loc[idx, f'{result_col_base}_unit'] = parsed.unit
                result_df.loc[idx, f'{result_col_base}_category'] = parsed.category
                result_df.loc[idx, f'{result_col_base}_is_bulk'] = parsed.is_bulk
                result_df.loc[idx, f'{result_col_base}_source'] = source_column
                
                # ë¡œê·¸ ì§‘ê³„
                if warnings:
                    parsing_log['warning_count'] += 1
                    parsing_log['warnings'].extend([f"í–‰ {idx+1} ({source_column}): {w}" for w in warnings])
                else:
                    parsing_log['success_count'] += 1
            
            # ì›ë³¸ ì»¬ëŸ¼ì„ íŒŒì‹±ëœ ê²°ê³¼ë¡œ ëŒ€ì²´
            if primary_col:
                result_df[primary_col] = result_df[f'{result_col_base}_parsed']
            elif fallback_col:
                result_df[fallback_col] = result_df[f'{result_col_base}_parsed']
            
        except Exception as e:
            parsing_log['error_count'] += 1
            parsing_log['errors'].append(f"ì „ì²´ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        
        return result_df, parsing_log

class PackingListGenerator:
    """íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.aggregation_data = defaultdict(lambda: {
            'quantity': 0,
            'total_weight': 0.0,
            'order_files': set(),
            'unit_weight': 0.0,
            'unit': 'KG',
            'category': '',
            'is_bulk': False
        })
        self.delivery_data = defaultdict(lambda: {
            'order_count': 0,
            'order_files': set()
        })
        self.total_orders_processed = 0
    
    def is_bulk_product(self, product_name: str, is_bulk_flag: bool) -> bool:
        """ì—…ì†Œìš© ìƒí’ˆ íŒë‹¨"""
        if is_bulk_flag:
            return True
        return 'ì—…ì†Œìš©' in product_name or '** ì—… ì†Œ ìš© **' in product_name
    
    def generate_aggregation_key(self, product_name: str, weight: str, category: str, is_bulk: bool) -> str:
        """ì§‘ê³„ í‚¤ ìƒì„±"""
        
        # ì—…ì†Œìš© ìƒí’ˆì´ë‚˜ ë§ˆëŠ˜ì«‘ì˜ ê²½ìš°: ìƒí’ˆëª… ê·¸ëŒ€ë¡œ
        if self.is_bulk_product(product_name, is_bulk) or category == 'ë§ˆëŠ˜ì«‘':
            return f"{category}_{product_name}"
        
        # ë‹­ë°œì˜ ê²½ìš°: ìˆ˜ëŸ‰ë§Œ ì§‘ê³„ (ë¬´ê²Œ ì •ë³´ ë¬´ì‹œ)
        elif category == 'ë‹­ë°œ':
            clean_name = self._remove_weight_from_name(product_name)
            return f"{category}_{clean_name}"
        
        # ì¼ë°˜ ìƒí’ˆ: ë¬´ê²Œ ì œê±°í•œ ìƒí’ˆëª…ìœ¼ë¡œ ê·¸ë£¹í™”
        else:
            clean_name = self._remove_weight_from_name(product_name)
            return f"{category}_{clean_name}"
    
    def _remove_weight_from_name(self, product_name: str) -> str:
        """ìƒí’ˆëª…ì—ì„œ ë¬´ê²Œ ì •ë³´ ì œê±°"""
        weight_patterns = [
            r'\d+(?:\.\d+)?\s*í‚¤ë¡œ\s*(?:ê·¸ë¨)?',
            r'\d+(?:\.\d+)?\s*(?:KG|kg)',
            r'\d+(?:\.\d+)?\s*(?:G|g|ê·¸ë¨)',
            r'\d+(?:\.\d+)?\s*(?:í‚¤|k)',
            r'\d+(?:\.\d+)?\s*(?:í‚¬ë¡œ|kilo)',
        ]
        
        clean_name = product_name
        for pattern in weight_patterns:
            clean_name = re.sub(pattern, '', clean_name, flags=re.IGNORECASE)
        
        # ë¶ˆí•„ìš”í•œ ê³µë°±ê³¼ ê¸°í˜¸ ì •ë¦¬
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()
        # ì•ë’¤ ê¸°í˜¸ ì œê±°
        clean_name = re.sub(r'^[,.\-\s]+|[,.\-\s]+$', '', clean_name).strip()
        
        return clean_name
    
    def find_delivery_columns(self, df: pd.DataFrame) -> Tuple[str, str]:
        """ë°°ì†¡ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°"""
        recipient_col = None
        address_col = None
        
        # ìˆ˜ë ¹ì¸ëª… ì»¬ëŸ¼ ì°¾ê¸°
        for col in df.columns:
            col_str = str(col).strip()
            if 'ìˆ˜ë ¹ì¸ëª…' in col_str or 'ë°›ëŠ”ë¶„' in col_str or 'ìˆ˜ë ¹ì¸' in col_str:
                recipient_col = col
                break
        
        # ì£¼ì†Œ ì»¬ëŸ¼ ì°¾ê¸°
        for col in df.columns:
            col_str = str(col).strip()
            if 'ì£¼ì†Œ' in col_str or 'ë°°ì†¡ì§€' in col_str or 'ë°°ì†¡ì£¼ì†Œ' in col_str:
                address_col = col
                break
        
        return recipient_col, address_col
    
    def add_order_data(self, df: pd.DataFrame, source_file: str):
        """ì£¼ë¬¸ ë°ì´í„° ì¶”ê°€"""
        # íŒŒì‹±ëœ ì»¬ëŸ¼ ì°¾ê¸°
        parsed_cols = {}
        for col in df.columns:
            if col.endswith('_parsed'):
                base_name = col[:-7]
                parsed_cols['parsed'] = col
                parsed_cols['weight'] = f"{base_name}_weight"
                parsed_cols['category'] = f"{base_name}_category"
                parsed_cols['is_bulk'] = f"{base_name}_is_bulk"
                break
        
        if not parsed_cols:
            st.error("íŒŒì‹±ëœ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì°¾ê¸°
        quantity_col = None
        for col in df.columns:
            if any(keyword in col.lower() for keyword in ['ìˆ˜ëŸ‰', 'qty', 'quantity', 'ê°œìˆ˜']):
                quantity_col = col
                break
        
        if not quantity_col:
            st.error("ìˆ˜ëŸ‰ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°°ì†¡ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
        recipient_col, address_col = self.find_delivery_columns(df)
        
        # ë°ì´í„° ì§‘ê³„
        for idx, row in df.iterrows():
            try:
                product_name = str(row[parsed_cols['parsed']])
                weight = str(row[parsed_cols['weight']])
                category = str(row[parsed_cols['category']])
                is_bulk = bool(row[parsed_cols['is_bulk']])
                quantity = int(row[quantity_col]) if pd.notna(row[quantity_col]) else 0
                
                if quantity <= 0 or not product_name or product_name == 'nan':
                    continue
                
                # ì „ì²´ ì£¼ë¬¸ ê±´ìˆ˜ ì¦ê°€
                self.total_orders_processed += 1
                
                # ì§‘ê³„ í‚¤ ìƒì„±
                agg_key = self.generate_aggregation_key(product_name, weight, category, is_bulk)
                
                # ìƒí’ˆ ë°ì´í„° ì§‘ê³„
                agg_data = self.aggregation_data[agg_key]
                agg_data['category'] = category
                agg_data['is_bulk'] = self.is_bulk_product(product_name, is_bulk)
                agg_data['order_files'].add(source_file)
                
                # ë¬´ê²Œì™€ ìˆ˜ëŸ‰ ì²˜ë¦¬
                if weight and weight != 'nan':
                    unit_weight = float(weight)
                    agg_data['unit_weight'] = unit_weight
                    
                    # ì—…ì†Œìš©, ë§ˆëŠ˜ì«‘: ìˆ˜ëŸ‰ë§Œ í•©ì‚°
                    if self.is_bulk_product(product_name, is_bulk) or category == 'ë§ˆëŠ˜ì«‘':
                        agg_data['quantity'] += quantity
                        agg_data['total_weight'] += unit_weight * quantity
                    # ë‹­ë°œ: ìˆ˜ëŸ‰ë§Œ í•©ì‚°, ë¬´ê²Œ ë¬´ì‹œ
                    elif category == 'ë‹­ë°œ':
                        agg_data['quantity'] += quantity
                        agg_data['total_weight'] = 0
                    # ì¼ë°˜ ìƒí’ˆ: ë¬´ê²Œ X ìˆ˜ëŸ‰ì„ 1KGë¡œ ë‚˜ëˆˆ ê°’
                    else:
                        final_quantity = (unit_weight * quantity) / 1.0
                        agg_data['quantity'] += final_quantity
                        agg_data['total_weight'] += unit_weight * quantity
                else:
                    # ë¬´ê²Œ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° (ë‹­ë°œ ë“±)
                    agg_data['quantity'] += quantity
                    if category == 'ë‹­ë°œ':
                        agg_data['total_weight'] = 0
                
                # ë°°ì†¡ ì •ë³´ ì§‘ê³„
                if recipient_col and address_col and recipient_col in df.columns and address_col in df.columns:
                    recipient = str(row[recipient_col]) if pd.notna(row[recipient_col]) else ""
                    address = str(row[address_col]) if pd.notna(row[address_col]) else ""
                    
                    if recipient and address and recipient != 'nan' and address != 'nan':
                        delivery_key = f"{recipient}_{address}"
                        delivery_data = self.delivery_data[delivery_key]
                        delivery_data['order_count'] += 1
                        delivery_data['order_files'].add(source_file)
                
            except Exception as e:
                continue
    
    def generate_packing_list(self) -> Tuple[List[PackingItem], PackingSummary]:
        """íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
        packing_items = []
        
        for agg_key, agg_data in self.aggregation_data.items():
            if agg_data['quantity'] > 0:
                key_parts = agg_key.split('_', 1)
                category = key_parts[0]
                raw_product_name = key_parts[1] if len(key_parts) > 1 else ""
                
                # í‘œì‹œí•  ìƒí’ˆëª… ê²°ì •
                if agg_data['is_bulk'] or category == 'ë§ˆëŠ˜ì«‘':
                    display_name = raw_product_name
                    display_quantity = int(agg_data['quantity'])
                else:
                    display_name = raw_product_name
                    display_quantity = agg_data['quantity']
                
                packing_item = PackingItem(
                    product_name=display_name,
                    category=category,
                    unit_weight=agg_data['unit_weight'],
                    unit=agg_data['unit'],
                    quantity=display_quantity,
                    total_weight=agg_data['total_weight'],
                    is_bulk=agg_data['is_bulk'],
                    order_files=list(agg_data['order_files'])
                )
                
                packing_items.append(packing_item)
        
        # íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ì •ë ¬ ê°œì„ : ê°™ì€ ì œí’ˆë¼ë¦¬ ê·¸ë£¹í•‘
        packing_items = sorted(packing_items, key=lambda x: (
            x.category,        # 1ìˆœìœ„: ì¹´í…Œê³ ë¦¬
            x.product_name     # 2ìˆœìœ„: ìƒí’ˆëª… (ê°™ì€ ì œí’ˆë¼ë¦¬ ë¬¶ì„)
        ))
        
        # ìš”ì•½ ì •ë³´ ìƒì„±
        summary = self._generate_summary(packing_items)
        
        return packing_items, summary
    
    def _generate_summary(self, items: List[PackingItem]) -> PackingSummary:
        """ìš”ì•½ ì •ë³´ ìƒì„±"""
        total_items = len(items)
        total_weight = sum(item.total_weight for item in items)
        
        bulk_items = [item for item in items if item.is_bulk]
        bulk_count = len(bulk_items)
        bulk_weight = sum(item.total_weight for item in bulk_items)
        
        regular_count = total_items - bulk_count
        regular_weight = total_weight - bulk_weight
        
        categories = defaultdict(int)
        for item in items:
            categories[item.category] += item.quantity
        
        # í•©ë°°ì†¡ ë¶„ì„
        combined_deliveries = sum(1 for delivery_data in self.delivery_data.values() if delivery_data['order_count'] > 1)
        unique_deliveries = len(self.delivery_data)
        
        return PackingSummary(
            total_items=total_items,
            total_weight=total_weight,
            bulk_items=bulk_count,
            bulk_weight=bulk_weight,
            regular_items=regular_count,
            regular_weight=regular_weight,
            categories=dict(categories),
            total_orders=self.total_orders_processed,
            combined_delivery_count=combined_deliveries,
            unique_delivery_locations=unique_deliveries
        )
    
    def get_statistics(self) -> Dict:
        """í˜„ì¬ ì§‘ê³„ í†µê³„ ë°˜í™˜"""
        total_orders = sum(data['quantity'] for data in self.aggregation_data.values())
        total_products = len(self.aggregation_data)
        total_weight = sum(data['total_weight'] for data in self.aggregation_data.values())
        
        categories = defaultdict(int)
        for data in self.aggregation_data.values():
            categories[data['category']] += data['quantity']
        
        # í•©ë°°ì†¡ í†µê³„
        combined_deliveries = sum(1 for delivery_data in self.delivery_data.values() if delivery_data['order_count'] > 1)
        unique_deliveries = len(self.delivery_data)
        
        return {
            'total_orders': total_orders,
            'total_products': total_products,
            'total_weight': total_weight,
            'categories': dict(categories),
            'files_processed': len(set().union(*(data['order_files'] for data in self.aggregation_data.values() if data['order_files']))),
            'total_orders_processed': self.total_orders_processed,
            'combined_deliveries': combined_deliveries,
            'unique_deliveries': unique_deliveries
        }
    
    def get_delivery_analysis(self) -> List[DeliveryInfo]:
        """ë°°ì†¡ ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        delivery_list = []
        
        for delivery_key, delivery_data in self.delivery_data.items():
            if '_' in delivery_key:
                recipient, address = delivery_key.split('_', 1)
                delivery_info = DeliveryInfo(
                    recipient_name=recipient,
                    address=address,
                    order_count=delivery_data['order_count'],
                    order_files=list(delivery_data['order_files'])
                )
                delivery_list.append(delivery_info)
        
        # ì£¼ë¬¸ ê±´ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ë§ì€ ìˆœ)
        delivery_list.sort(key=lambda x: x.order_count, reverse=True)
        
        return delivery_list
    
    def clear_data(self):
        """ì§‘ê³„ ë°ì´í„° ì´ˆê¸°í™”"""
        self.aggregation_data.clear()
        self.delivery_data.clear()
        self.total_orders_processed = 0

# ìƒ‰ìƒ í‘œì‹œ ê´€ë ¨ í•¨ìˆ˜ë“¤ - ì™„ì „ ë³µì›
def find_combined_delivery_rows(df: pd.DataFrame) -> list:
    """í•©ë°°ì†¡ í–‰ë“¤ì˜ ì¸ë±ìŠ¤ ì°¾ê¸° (ë…¸ë€ìƒ‰ ìƒ‰ì¹ ìš©)"""
    try:
        # ë°°ì†¡ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
        recipient_col = None
        address_col = None
        phone_col = None
        
        for col in df.columns:
            col_clean = re.sub(r'[\s\-_]+', '', str(col).strip())
            
            if not recipient_col:
                recipient_keywords = ['ìˆ˜ì·¨ì¸ëª…', 'ìˆ˜ì·¨ì¸', 'ìˆ˜ë ¹ì¸ëª…']
                if col_clean in recipient_keywords:
                    recipient_col = col
            
            if not address_col:
                address_keywords = ['ì£¼ì†Œ', 'ê¸°ë³¸ë°°ì†¡ì§€', 'ë°°ì†¡ì§€ì£¼ì†Œ']
                if col_clean in address_keywords:
                    address_col = col
            
            if not phone_col:
                phone_keywords = ['ìˆ˜ë ¹ì¸ì—°ë½ì²˜1', 'ìˆ˜ì·¨ì¸ì—°ë½ì²˜1', 'ìˆ˜ë ¹ì¸íœ´ëŒ€í°', 'íœ´ëŒ€í°ë²ˆí˜¸']
                if col_clean in phone_keywords:
                    phone_col = col
        
        # 3ê°œ ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆì–´ì•¼ í•©ë°°ì†¡ ì²´í¬ ê°€ëŠ¥
        if not (recipient_col and address_col and phone_col):
            return []
        
        # ë°°ì†¡ ê·¸ë£¹ ìƒì„±
        delivery_groups = {}
        
        for idx, row in df.iterrows():
            recipient = str(row[recipient_col]) if pd.notna(row[recipient_col]) else ""
            address = str(row[address_col]) if pd.notna(row[address_col]) else ""
            phone = str(row[phone_col]) if pd.notna(row[phone_col]) else ""
            
            # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì²˜ë¦¬
            if recipient and address and phone and recipient != 'nan' and address != 'nan' and phone != 'nan':
                delivery_key = f"{recipient}_{address}_{phone}"
                
                if delivery_key not in delivery_groups:
                    delivery_groups[delivery_key] = []
                delivery_groups[delivery_key].append(idx)
        
        # í•©ë°°ì†¡ í–‰ë“¤ ì°¾ê¸° (2ê°œ ì´ìƒì˜ ì£¼ë¬¸ì´ ìˆëŠ” ê·¸ë£¹)
        combined_rows = []
        for group_rows in delivery_groups.values():
            if len(group_rows) > 1:  # í•©ë°°ì†¡ì¸ ê²½ìš°
                combined_rows.extend(group_rows)
        
        return combined_rows
        
    except Exception as e:
        return []

def find_heavy_order_rows(df: pd.DataFrame) -> list:
    """10kg ì´ˆê³¼ ì£¼ë¬¸ í–‰ë“¤ì˜ ì¸ë±ìŠ¤ ì°¾ê¸° (ì—°ë‘ìƒ‰ ìƒ‰ì¹ ìš©)"""
    try:
        heavy_rows = []
        
        # ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì°¾ê¸°
        quantity_col = None
        for col in df.columns:
            if any(keyword in col.lower() for keyword in ['ìˆ˜ëŸ‰', 'qty', 'quantity', 'ê°œìˆ˜']):
                quantity_col = col
                break
        
        # ë¬´ê²Œ ì»¬ëŸ¼ ì°¾ê¸°
        weight_col = None
        for col in df.columns:
            if col.endswith('_weight'):
                weight_col = col
                break
        
        if not quantity_col or not weight_col:
            return []
        
        # ê° í–‰ì—ì„œ 10kg ì´ˆê³¼ ì²´í¬
        for idx, row in df.iterrows():
            try:
                quantity = pd.to_numeric(row[quantity_col], errors='coerce')
                unit_weight = pd.to_numeric(row[weight_col], errors='coerce')
                
                if pd.notna(quantity) and pd.notna(unit_weight):
                    total_weight = quantity * unit_weight
                    if total_weight > 10.0:
                        heavy_rows.append(idx)
            except:
                continue
        
        return heavy_rows
        
    except Exception as e:
        return []

# ì •ë ¬ í•¨ìˆ˜ë“¤ - ì™„ì „ ë³µì›
def apply_sorting_to_parsed_file(df: pd.DataFrame) -> pd.DataFrame:
    """íŒŒì‹±ëœ íŒŒì¼ì— ì •ë ¬ ì ìš© - ì „ì²´ í–‰ ë°ì´í„° í•¨ê»˜ ì •ë ¬ (ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥)"""
    try:
        # ì›ë³¸ DataFrameì˜ ì™„ì „í•œ ë³µì‚¬ë³¸ ìƒì„± (ëª¨ë“  ë°ì´í„° ë³´ì¡´)
        df_original = df.copy()
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ ì°¾ê¸°
        parsed_col = None
        quantity_col = None
        
        # íŒŒì‹±ëœ ìƒí’ˆëª… ì»¬ëŸ¼ ì°¾ê¸°
        for col in df_original.columns:
            if col.endswith('_parsed'):
                parsed_col = col
                break
        
        # ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì°¾ê¸°
        for col in df_original.columns:
            if any(keyword in col.lower() for keyword in ['ìˆ˜ëŸ‰', 'qty', 'quantity', 'ê°œìˆ˜']):
                quantity_col = col
                break
        
        if not parsed_col or not quantity_col:
            st.warning(f"âš ï¸ ì •ë ¬ì— í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì‹±ì»¬ëŸ¼: {parsed_col}, ìˆ˜ëŸ‰ì»¬ëŸ¼: {quantity_col}")
            return df_original
        
        # ë°°ì†¡ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
        recipient_col = None
        address_col = None
        phone_col = None
        
        for col in df_original.columns:
            col_clean = re.sub(r'[\s\-_]+', '', str(col).strip())
            
            if not recipient_col:
                recipient_keywords = ['ìˆ˜ì·¨ì¸ëª…', 'ìˆ˜ì·¨ì¸', 'ìˆ˜ë ¹ì¸ëª…']
                if col_clean in recipient_keywords:
                    recipient_col = col
            
            if not address_col:
                address_keywords = ['ì£¼ì†Œ', 'ê¸°ë³¸ë°°ì†¡ì§€', 'ë°°ì†¡ì§€ì£¼ì†Œ']
                if col_clean in address_keywords:
                    address_col = col
            
            if not phone_col:
                phone_keywords = ['ìˆ˜ë ¹ì¸ì—°ë½ì²˜1', 'ìˆ˜ì·¨ì¸ì—°ë½ì²˜1', 'ìˆ˜ë ¹ì¸íœ´ëŒ€í°', 'íœ´ëŒ€í°ë²ˆí˜¸']
                if col_clean in phone_keywords:
                    phone_col = col
        
        # ê°„ë‹¨í•œ ì •ë³´ë§Œ ì¶œë ¥
        st.info(f"ğŸ”§ ì •ë ¬ ê¸°ì¤€: {parsed_col} (ìˆ˜ëŸ‰: {quantity_col})")
        
        # â­ í•µì‹¬: ì›ë³¸ ì¸ë±ìŠ¤ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì •ë ¬ìš© ì»¬ëŸ¼ë§Œ ì¶”ê°€
        df_for_sorting = df_original.copy()
        
        # í•©ë°°ì†¡ ì—¬ë¶€ íŒë‹¨
        has_combined_delivery = False
        
        if recipient_col and address_col and phone_col:
            # ë°°ì†¡ í‚¤ ìƒì„±
            df_for_sorting['_temp_delivery_key'] = (
                df_for_sorting[recipient_col].astype(str) + '_' + 
                df_for_sorting[address_col].astype(str) + '_' + 
                df_for_sorting[phone_col].astype(str)
            )
            
            # í•©ë°°ì†¡ ê±´ìˆ˜ ê³„ì‚°
            delivery_counts = df_for_sorting['_temp_delivery_key'].value_counts()
            df_for_sorting['_temp_is_combined'] = df_for_sorting['_temp_delivery_key'].map(lambda x: delivery_counts[x] > 1)
            
            # ì‹¤ì œ í•©ë°°ì†¡ì´ ìˆëŠ”ì§€ í™•ì¸
            has_combined_delivery = df_for_sorting['_temp_is_combined'].any()
            
            if has_combined_delivery:
                combined_count = delivery_counts[delivery_counts > 1].sum()
                st.success(f"ğŸšš í•©ë°°ì†¡ ê°ì§€: {combined_count}ê±´ â†’ ìƒë‹¨ ê³ ì • ì •ë ¬")
        
        # â­ 10kg ì´ˆê³¼ ì£¼ë¬¸ ê°ì§€ (ì—°ë‘ìƒ‰ í‘œì‹œìš©)
        df_for_sorting['_temp_is_heavy'] = False
        if quantity_col in df_for_sorting.columns:
            try:
                for idx, row in df_for_sorting.iterrows():
                    quantity = pd.to_numeric(row[quantity_col], errors='coerce')
                    # íŒŒì‹±ëœ ë¬´ê²Œ ì •ë³´ ì°¾ê¸°
                    weight_col = None
                    for col in df_for_sorting.columns:
                        if col.endswith('_weight'):
                            weight_col = col
                            break
                    
                    if weight_col and pd.notna(row[weight_col]) and pd.notna(quantity):
                        unit_weight = pd.to_numeric(row[weight_col], errors='coerce')
                        total_weight = quantity * unit_weight
                        if total_weight > 10.0:
                            df_for_sorting.loc[idx, '_temp_is_heavy'] = True
            except:
                pass  # ì˜¤ë¥˜ ì‹œ ë¬´ì‹œ
        
        heavy_count = df_for_sorting['_temp_is_heavy'].sum()
        if heavy_count > 0:
            st.info(f"ğŸŸ¢ 10kg ì´ˆê³¼ ì£¼ë¬¸ ê°ì§€: {heavy_count}ê±´ â†’ ì—°ë‘ìƒ‰ í‘œì‹œ")
        
        # ìˆ˜ëŸ‰ì„ ìˆ«ìë¡œ ë³€í™˜ (ì •ë ¬ìš©)
        df_for_sorting['_temp_quantity_sort'] = pd.to_numeric(df_for_sorting[quantity_col], errors='coerce').fillna(0)
        
        # â­â­â­ ìˆ˜ì •ëœ ì •ë ¬: ì œí’ˆëª… â†’ ìˆ˜ëŸ‰ ìˆœìœ¼ë¡œ ë³€ê²½
        if has_combined_delivery:
            # í•©ë°°ì†¡ì´ ìˆëŠ” ê²½ìš°: í•©ë°°ì†¡ ìƒë‹¨ ê³ ì • + ì œí’ˆëª… + ìˆ˜ëŸ‰ìˆœ
            sort_columns = ['_temp_is_combined', parsed_col, '_temp_quantity_sort']
            sort_ascending = [False, True, True]  # í•©ë°°ì†¡ ìƒë‹¨, ì œí’ˆëª… ê°€ë‚˜ë‹¤ìˆœ, ìˆ˜ëŸ‰ ì ì€ìˆœ
            st.info("ğŸ“‹ ì •ë ¬ ìˆœì„œ: í•©ë°°ì†¡ ìƒë‹¨ ê³ ì • â†’ ì œí’ˆëª… ê°€ë‚˜ë‹¤ìˆœ â†’ ìˆ˜ëŸ‰ ì ì€ìˆœ")
        else:
            # í•©ë°°ì†¡ì´ ì—†ëŠ” ê²½ìš°: ì œí’ˆëª… + ìˆ˜ëŸ‰ìˆœ
            sort_columns = [parsed_col, '_temp_quantity_sort']
            sort_ascending = [True, True]  # ì œí’ˆëª… ê°€ë‚˜ë‹¤ìˆœ, ìˆ˜ëŸ‰ ì ì€ìˆœ
            st.info("ğŸ“‹ ì •ë ¬ ìˆœì„œ: ì œí’ˆëª… ê°€ë‚˜ë‹¤ìˆœ â†’ ìˆ˜ëŸ‰ ì ì€ìˆœ")
        
        # âœ… ì „ì²´ ì •ë ¬ ì‹¤í–‰ - ëª¨ë“  ì›ë³¸ ë°ì´í„°ê°€ í–‰ë³„ë¡œ í•¨ê»˜ ì›€ì§ì„ (ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥)
        sorted_df = df_for_sorting.sort_values(
            sort_columns,
            ascending=sort_ascending,
            na_position='last'
        ).reset_index(drop=True)
        
        # ì„ì‹œ ì •ë ¬ìš© ì»¬ëŸ¼ë“¤ë§Œ ì œê±° (ì›ë³¸ ë°ì´í„°ëŠ” ëª¨ë‘ ë³´ì¡´)
        temp_columns = ['_temp_delivery_key', '_temp_is_combined', '_temp_quantity_sort', '_temp_is_heavy']
        for temp_col in temp_columns:
            if temp_col in sorted_df.columns:
                sorted_df = sorted_df.drop(columns=[temp_col])
        
        # ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        original_shape = df_original.shape
        sorted_shape = sorted_df.shape
        
        if original_shape != sorted_shape:
            st.error(f"âŒ ë°ì´í„° ë¬´ê²°ì„± ì˜¤ë¥˜: ì›ë³¸ {original_shape} â‰  ì •ë ¬í›„ {sorted_shape}")
            return df_original
        
        st.success(f"âœ… ì „ì²´ {len(sorted_df)}í–‰ Ã— {len(sorted_df.columns)}ì—´ ì •ë ¬ ì™„ë£Œ (ëª¨ë“  ë°ì´í„° ë™ê¸°í™”)")
        
        return sorted_df
        
    except Exception as e:
        st.error(f"ì •ë ¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return df

def apply_sorting_to_parsed_file_silent(df: pd.DataFrame) -> pd.DataFrame:
    """ì •ë ¬ í•¨ìˆ˜ì˜ ì¡°ìš©í•œ ë²„ì „ (ì¼ê´„ ì²˜ë¦¬ìš© - ì¶œë ¥ ì—†ìŒ)"""
    try:
        # ì›ë³¸ DataFrameì˜ ì™„ì „í•œ ë³µì‚¬ë³¸ ìƒì„±
        df_original = df.copy()
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ ì°¾ê¸°
        parsed_col = None
        quantity_col = None
        
        for col in df_original.columns:
            if col.endswith('_parsed'):
                parsed_col = col
                break
        
        for col in df_original.columns:
            if any(keyword in col.lower() for keyword in ['ìˆ˜ëŸ‰', 'qty', 'quantity', 'ê°œìˆ˜']):
                quantity_col = col
                break
        
        if not parsed_col or not quantity_col:
            return df_original
        
        # ë°°ì†¡ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
        recipient_col = None
        address_col = None
        phone_col = None
        
        for col in df_original.columns:
            col_clean = re.sub(r'[\s\-_]+', '', str(col).strip())
            
            if not recipient_col:
                recipient_keywords = ['ìˆ˜ì·¨ì¸ëª…', 'ìˆ˜ì·¨ì¸', 'ìˆ˜ë ¹ì¸ëª…']
                if col_clean in recipient_keywords:
                    recipient_col = col
            
            if not address_col:
                address_keywords = ['ì£¼ì†Œ', 'ê¸°ë³¸ë°°ì†¡ì§€', 'ë°°ì†¡ì§€ì£¼ì†Œ']
                if col_clean in address_keywords:
                    address_col = col
            
            if not phone_col:
                phone_keywords = ['ìˆ˜ë ¹ì¸ì—°ë½ì²˜1', 'ìˆ˜ì·¨ì¸ì—°ë½ì²˜1', 'ìˆ˜ë ¹ì¸íœ´ëŒ€í°', 'íœ´ëŒ€í°ë²ˆí˜¸']
                if col_clean in phone_keywords:
                    phone_col = col
        
        # ì •ë ¬ìš© DataFrame ìƒì„± (ëª¨ë“  ì›ë³¸ ë°ì´í„° í¬í•¨)
        df_for_sorting = df_original.copy()
        
        # í•©ë°°ì†¡ ì²˜ë¦¬
        has_combined_delivery = False
        
        if recipient_col and address_col and phone_col:
            df_for_sorting['_temp_delivery_key'] = (
                df_for_sorting[recipient_col].astype(str) + '_' + 
                df_for_sorting[address_col].astype(str) + '_' + 
                df_for_sorting[phone_col].astype(str)
            )
            
            delivery_counts = df_for_sorting['_temp_delivery_key'].value_counts()
            df_for_sorting['_temp_is_combined'] = df_for_sorting['_temp_delivery_key'].map(lambda x: delivery_counts[x] > 1)
            has_combined_delivery = df_for_sorting['_temp_is_combined'].any()
        
        # â­ 10kg ì´ˆê³¼ ì£¼ë¬¸ ì²˜ë¦¬ (ì—°ë‘ìƒ‰ìš©)
        df_for_sorting['_temp_is_heavy'] = False
        if quantity_col in df_for_sorting.columns:
            try:
                for idx, row in df_for_sorting.iterrows():
                    quantity = pd.to_numeric(row[quantity_col], errors='coerce')
                    weight_col = None
                    for col in df_for_sorting.columns:
                        if col.endswith('_weight'):
                            weight_col = col
                            break
                    
                    if weight_col and pd.notna(row[weight_col]) and pd.notna(quantity):
                        unit_weight = pd.to_numeric(row[weight_col], errors='coerce')
                        total_weight = quantity * unit_weight
                        if total_weight > 10.0:
                            df_for_sorting.loc[idx, '_temp_is_heavy'] = True
            except:
                pass

        # ìˆ˜ëŸ‰ ë³€í™˜
        df_for_sorting['_temp_quantity_sort'] = pd.to_numeric(df_for_sorting[quantity_col], errors='coerce').fillna(0)
        
        # â­ ìˆ˜ì •ëœ ì •ë ¬: ì œí’ˆëª… â†’ ìˆ˜ëŸ‰ ìˆœ
        if has_combined_delivery:
            sort_columns = ['_temp_is_combined', parsed_col, '_temp_quantity_sort']
            sort_ascending = [False, True, True]
        else:
            sort_columns = [parsed_col, '_temp_quantity_sort']
            sort_ascending = [True, True]
        
        # âœ… ì „ì²´ í–‰ ì •ë ¬ (ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥)
        sorted_df = df_for_sorting.sort_values(
            sort_columns,
            ascending=sort_ascending,
            na_position='last'
        ).reset_index(drop=True)
        
        # ì„ì‹œ ì»¬ëŸ¼ë“¤ë§Œ ì œê±°
        temp_columns = ['_temp_delivery_key', '_temp_is_combined', '_temp_quantity_sort', '_temp_is_heavy']
        for temp_col in temp_columns:
            if temp_col in sorted_df.columns:
                sorted_df = sorted_df.drop(columns=[temp_col])
        
        return sorted_df
        
    except Exception as e:
        return df

# Streamlit ì•±
def setup_page():
    """í˜ì´ì§€ ì„¤ì •"""
    st.set_page_config(
        page_title="ë§ˆëŠ˜ ì£¼ë¬¸ì„œ ìë™ íŒŒì„œ & íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ìƒì„±ê¸°",
        page_icon="ğŸ§„",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ§„ ë§ˆëŠ˜ ì£¼ë¬¸ì„œ ìë™ íŒŒì„œ ë° íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ìƒì„±ê¸° (v3.0)")
    st.markdown("---")

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'parser' not in st.session_state:
        st.session_state.parser = GarlicOrderParser()
    
    if 'packing_generator' not in st.session_state:
        st.session_state.packing_generator = PackingListGenerator()
    
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = {}
    
    if 'parsing_logs' not in st.session_state:
        st.session_state.parsing_logs = {}

def display_sidebar():
    """ì‚¬ì´ë“œë°” í‘œì‹œ"""
    with st.sidebar:
        st.header("ğŸ“‹ ì²˜ë¦¬ í˜„í™©")
        
        stats = st.session_state.packing_generator.get_statistics()
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì²˜ë¦¬ëœ íŒŒì¼", stats['files_processed'])
            st.metric("ì „ì²´ ì£¼ë¬¸ ê±´ìˆ˜", stats['total_orders_processed'])
            st.metric("ì´ ìƒí’ˆ ì¢…ë¥˜", stats['total_products'])
        
        with col2:
            st.metric("ì´ ì£¼ë¬¸ ìˆ˜ëŸ‰", stats['total_orders'])
            st.metric("ì´ ë¬´ê²Œ(KG)", f"{stats['total_weight']:.1f}")
            st.metric("ê³ ìœ  ë°°ì†¡ì§€", stats['unique_deliveries'])
        
        # í•©ë°°ì†¡ ì •ë³´
        if stats['combined_deliveries'] > 0:
            st.markdown("### ğŸšš ë°°ì†¡ ì •ë³´")
            st.metric("í•©ë°°ì†¡ ê±´", stats['combined_deliveries'])
            st.write(f"â€¢ ì´ ë°°ì†¡ì§€: {stats['unique_deliveries']}ê³³")
            st.write(f"â€¢ í•©ë°°ì†¡ë¥ : {(stats['combined_deliveries']/stats['unique_deliveries']*100):.1f}%" if stats['unique_deliveries'] > 0 else "â€¢ í•©ë°°ì†¡ë¥ : 0%")
        
        if stats['categories']:
            st.subheader("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í˜„í™©")
            for category, qty in stats['categories'].items():
                if isinstance(qty, float):
                    st.write(f"â€¢ {category}: {qty:.0f}ê°œ")
                else:
                    st.write(f"â€¢ {category}: {qty}ê°œ")
        
        st.markdown("---")
        
        if st.button("ğŸ”„ ë°ì´í„° ì´ˆê¸°í™”", type="secondary"):
            st.session_state.packing_generator.clear_data()
            st.session_state.processed_files.clear()
            st.session_state.parsing_logs.clear()
            st.rerun()

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    setup_page()
    initialize_session_state()
    
    # ì‚¬ì´ë“œë°”
    display_sidebar()
    
    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    st.header("ğŸ“ 1. ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ")
    
    uploaded_files = st.file_uploader(
        "ë§ˆëŠ˜ ì£¼ë¬¸ì„œ ì—‘ì…€ íŒŒì¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
        type=['xlsx', 'xls'],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ ê°œì˜ ì—‘ì…€ íŒŒì¼ì„ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
    
    if uploaded_files:
        st.success(f"ğŸ“ {len(uploaded_files)}ê°œ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # íŒŒì‹± ì„¹ì…˜
        st.header("âš™ï¸ 2. ì£¼ë¬¸ì„œ íŒŒì‹±")
        
        if st.button("ğŸš€ íŒŒì‹± ì‹œì‘", type="primary"):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, file in enumerate(uploaded_files):
                status_text.text(f"ì²˜ë¦¬ ì¤‘: {file.name}")
                
                try:
                    df = pd.read_excel(file)
                    
                    st.subheader(f"ğŸ” {file.name} íŒŒì‹± ê²°ê³¼")
                    
                    parsed_df, parsing_log = st.session_state.parser.parse_dataframe(df)
                    
                    # íŒŒì‹± ë¡œê·¸ í‘œì‹œ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì„±ê³µ", parsing_log['success_count'])
                    with col2:
                        st.metric("ê²½ê³ ", parsing_log['warning_count'])
                    with col3:
                        st.metric("ì˜¤ë¥˜", parsing_log['error_count'])
                    
                    if parsing_log.get('primary_column'):
                        st.success(f"ì£¼ìš” ì»¬ëŸ¼ì—ì„œ íŒŒì‹±: {parsing_log['primary_column']}")
                    if parsing_log.get('fallback_column'):
                        st.info(f"ë³´ì¡° ì»¬ëŸ¼ ì‚¬ìš© ê°€ëŠ¥: {parsing_log['fallback_column']}")
                    
                    if parsing_log.get('errors'):
                        st.error("ì˜¤ë¥˜ ë°œìƒ:")
                        for error in parsing_log['errors']:
                            st.write(f"  â€¢ {error}")
                    
                    st.session_state.processed_files[file.name] = {
                        'original_df': df,
                        'parsed_df': parsed_df,
                        'file_obj': file
                    }
                    st.session_state.parsing_logs[file.name] = parsing_log
                    
                    st.session_state.packing_generator.add_order_data(parsed_df, file.name)
                    
                except Exception as e:
                    st.error(f"âŒ {file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
                    continue
                
                progress_bar.progress((i + 1) / len(uploaded_files))
            
            status_text.text("âœ… ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
            st.success("íŒŒì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    # íŒŒì‹± ê²°ê³¼ í‘œì‹œ
    if st.session_state.processed_files:
        st.header("ğŸ“Š 3. íŒŒì‹± ê²°ê³¼")
        
        for filename, file_data in st.session_state.processed_files.items():
            with st.expander(f"ğŸ“„ {filename} ê²°ê³¼"):
                log = st.session_state.parsing_logs.get(filename, {})
                
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    # íŒŒì‹± ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                    if st.checkbox(f"ë¯¸ë¦¬ë³´ê¸° - {filename}", key=f"preview_{filename}"):
                        original_df = file_data['original_df']
                        parsed_df = file_data['parsed_df']
                        
                        st.markdown("##### íŒŒì‹± ì „/í›„ ë¹„êµ")
                        compare_cols = st.columns(2)
                        
                        with compare_cols[0]:
                            st.markdown("**íŒŒì‹± ì „ (ì²˜ìŒ 5í–‰)**")
                            st.dataframe(original_df.head(5), use_container_width=True)
                        
                        with compare_cols[1]:
                            st.markdown("**íŒŒì‹± í›„ (ì²˜ìŒ 5í–‰)**")
                            # ì£¼ìš” ì»¬ëŸ¼ë§Œ í‘œì‹œ
                            display_cols = []
                            for col in parsed_df.columns:
                                if any(suffix in col for suffix in ['_parsed', '_weight', '_category', '_is_bulk']) or col in ['ìˆ˜ëŸ‰', 'ìˆ˜ë ¹ì¸ëª…', 'ì£¼ì†Œ']:
                                    display_cols.append(col)
                            
                            if display_cols:
                                st.dataframe(parsed_df[display_cols].head(5), use_container_width=True)
                            else:
                                st.dataframe(parsed_df.head(5), use_container_width=True)
                
                with col2:
                    # ì •ë ¬ëœ íŒŒì‹± íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ìƒ‰ìƒ í‘œì‹œ í¬í•¨) - ì™„ì „ ë³µì›
                    parsed_df = file_data['parsed_df'].copy()
                    
                    # ì •ë ¬ ì²˜ë¦¬
                    sorted_df = apply_sorting_to_parsed_file(parsed_df)
                    
                    # ìƒ‰ìƒ í‘œì‹œë¥¼ ìœ„í•œ ì—‘ì…€ íŒŒì¼ ìƒì„±
                    output = io.BytesIO()
                    
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        sorted_df.to_excel(writer, sheet_name='íŒŒì‹±ê²°ê³¼_ì •ë ¬ë¨', index=False)
                        
                        # ìƒ‰ìƒ í‘œì‹œ ì ìš©
                        workbook = writer.book
                        worksheet = writer.sheets['íŒŒì‹±ê²°ê³¼_ì •ë ¬ë¨']
                        
                        # í•©ë°°ì†¡ ê·¸ë£¹ ì°¾ê¸° (ìƒ‰ì¹ ìš©)
                        combined_rows = find_combined_delivery_rows(sorted_df)
                        heavy_rows = find_heavy_order_rows(sorted_df)  # 10kg ì´ˆê³¼ ì£¼ë¬¸ ì°¾ê¸°
                        
                        if combined_rows or heavy_rows:
                            from openpyxl.styles import PatternFill
                            
                            # ìƒ‰ìƒ ì •ì˜
                            yellow_fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")  # í•©ë°°ì†¡ - ë…¸ë€ìƒ‰
                            green_fill = PatternFill(start_color="90EE90", end_color="90EE90", fill_type="solid")    # 10kg ì´ˆê³¼ - ì—°ë‘ìƒ‰
                            red_fill = PatternFill(start_color="FFB3B3", end_color="FFB3B3", fill_type="solid")      # í•©ë°°ì†¡+10kg - ì—°í•œ ë¹¨ê°„ìƒ‰
                            
                            # ê²¹ì¹˜ëŠ” í–‰ë“¤ ì°¾ê¸° (í•©ë°°ì†¡ + 10kg ì´ˆê³¼)
                            overlap_rows = list(set(combined_rows) & set(heavy_rows))
                            
                            # ìƒ‰ì¹  ì ìš©
                            for row_idx in range(len(sorted_df)):
                                excel_row = row_idx + 2  # í—¤ë” ë•Œë¬¸ì— +2
                                
                                if row_idx in overlap_rows:
                                    # í•©ë°°ì†¡ + 10kg ì´ˆê³¼ = ì—°í•œ ë¹¨ê°„ìƒ‰
                                    fill = red_fill
                                elif row_idx in combined_rows:
                                    # í•©ë°°ì†¡ë§Œ = ë…¸ë€ìƒ‰
                                    fill = yellow_fill
                                elif row_idx in heavy_rows:
                                    # 10kg ì´ˆê³¼ë§Œ = ì—°ë‘ìƒ‰
                                    fill = green_fill
                                else:
                                    continue
                                
                                # í•´ë‹¹ í–‰ì˜ ëª¨ë“  ì…€ì— ìƒ‰ì¹ 
                                for col_idx in range(1, len(sorted_df.columns) + 1):
                                    cell = worksheet.cell(row=excel_row, column=col_idx)
                                    cell.fill = fill
                    
                    output.seek(0)
                    
                    download_filename = f"{filename.split('.')[0]}_parsed_sorted.xlsx"
                    
                    st.download_button(
                        label="ğŸ“ ì •ë ¬ëœ íŒŒì‹± ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                        data=output.getvalue(),
                        file_name=download_filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"download_{filename}"
                    )
                    
                    st.caption("âœ¨ ì œí’ˆëª… â†’ ìˆ˜ëŸ‰ìˆœ ìë™ ì •ë ¬")
                    st.caption("ğŸ¨ í•©ë°°ì†¡: ë…¸ë€ìƒ‰ | 10kgì´ˆê³¼: ì—°ë‘ìƒ‰ | ë‘˜ë‹¤: ì—°í•œë¹¨ê°•")
        
        # ì „ì²´ íŒŒì¼ ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ - ì™„ì „ ë³µì›
        if len(st.session_state.processed_files) > 1:
            st.markdown("---")
            st.subheader("ğŸ“¦ ì „ì²´ íŒŒì¼ ì¼ê´„ ë‹¤ìš´ë¡œë“œ")
            
            if st.button("ğŸ“ ëª¨ë“  ì •ë ¬ëœ íŒŒì¼ í•œë²ˆì— ë‹¤ìš´ë¡œë“œ", type="secondary"):
                try:
                    # ëª¨ë“  íŒŒì¼ì„ ì²˜ë¦¬í•´ì„œ ZIP ìƒì„±
                    import zipfile
                    
                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # ì„ì‹œ ZIP íŒŒì¼ ìƒì„±
                    zip_buffer = io.BytesIO()
                    
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
                        total_files = len(st.session_state.processed_files)
                        
                        for i, (filename, file_data) in enumerate(st.session_state.processed_files.items()):
                            status_text.text(f"ì²˜ë¦¬ ì¤‘: {filename}")
                            
                            # ê° íŒŒì¼ ì •ë ¬ ì²˜ë¦¬ (ë””ë²„ê¹… ì¶œë ¥ ì–µì œ)
                            parsed_df = file_data['parsed_df'].copy()
                            sorted_df = apply_sorting_to_parsed_file_silent(parsed_df)
                            
                            # ë©”ëª¨ë¦¬ ë‚´ì—ì„œ ì—‘ì…€ íŒŒì¼ ìƒì„± (ìƒ‰ìƒ í‘œì‹œ í¬í•¨)
                            excel_buffer = io.BytesIO()
                            
                            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                sorted_df.to_excel(writer, sheet_name='íŒŒì‹±ê²°ê³¼_ì •ë ¬ë¨', index=False)
                                
                                # ìƒ‰ìƒ í‘œì‹œ ì ìš©
                                workbook = writer.book
                                worksheet = writer.sheets['íŒŒì‹±ê²°ê³¼_ì •ë ¬ë¨']
                                
                                combined_rows = find_combined_delivery_rows(sorted_df)
                                heavy_rows = find_heavy_order_rows(sorted_df)
                                
                                if combined_rows or heavy_rows:
                                    from openpyxl.styles import PatternFill
                                    
                                    yellow_fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")
                                    green_fill = PatternFill(start_color="90EE90", end_color="90EE90", fill_type="solid")
                                    red_fill = PatternFill(start_color="FFB3B3", end_color="FFB3B3", fill_type="solid")
                                    
                                    overlap_rows = list(set(combined_rows) & set(heavy_rows))
                                    
                                    for row_idx in range(len(sorted_df)):
                                        excel_row = row_idx + 2
                                        
                                        if row_idx in overlap_rows:
                                            fill = red_fill
                                        elif row_idx in combined_rows:
                                            fill = yellow_fill
                                        elif row_idx in heavy_rows:
                                            fill = green_fill
                                        else:
                                            continue
                                        
                                        for col_idx in range(1, len(sorted_df.columns) + 1):
                                            cell = worksheet.cell(row=excel_row, column=col_idx)
                                            cell.fill = fill
                            
                            # ZIPì— íŒŒì¼ ì¶”ê°€ (ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘)
                            zip_filename = f"{filename.split('.')[0]}_parsed_sorted.xlsx"
                            zipf.writestr(zip_filename, excel_buffer.getvalue())
                            
                            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                            progress_bar.progress((i + 1) / total_files)
                    
                    # ZIP íŒŒì¼ ì™„ì„±
                    zip_buffer.seek(0)
                    
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    zip_filename = f"ì „ì²´_íŒŒì‹±ê²°ê³¼_{timestamp}.zip"
                    
                    status_text.text("âœ… ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ!")
                    progress_bar.progress(100)
                    
                    st.download_button(
                        label="ğŸ’¾ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=zip_buffer.getvalue(),
                        file_name=zip_filename,
                        mime="application/zip"
                    )
                    
                    st.success(f"âœ… {len(st.session_state.processed_files)}ê°œ íŒŒì¼ì´ ZIPìœ¼ë¡œ íŒ¨í‚¤ì§•ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                except Exception as e:
                    st.error(f"ZIP ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
        
        # íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ì„¹ì…˜
        st.header("ğŸ“¦ 4. íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ìƒì„±")
        
        col1, col2 = st.columns([2, 1])
        
        with col2:
            st.markdown("### ğŸ“Š í˜„ì¬ ì§‘ê³„ í˜„í™©")
            stats = st.session_state.packing_generator.get_statistics()
            
            st.metric("ì²˜ë¦¬ëœ íŒŒì¼", stats['files_processed'])
            st.metric("ì „ì²´ ì£¼ë¬¸ ê±´ìˆ˜", stats['total_orders_processed'])
            st.metric("ìƒí’ˆ ì¢…ë¥˜", stats['total_products'])
            st.metric("ì´ ìˆ˜ëŸ‰", stats['total_orders'])
            st.metric("ì´ ë¬´ê²Œ", f"{stats['total_weight']:.1f} KG")
            
            # ë°°ì†¡ ì •ë³´
            if stats['unique_deliveries'] > 0:
                st.markdown("#### ğŸšš ë°°ì†¡ ì •ë³´")
                st.metric("ê³ ìœ  ë°°ì†¡ì§€", stats['unique_deliveries'])
                st.metric("í•©ë°°ì†¡ ê±´", stats['combined_deliveries'])
        
        with col1:
            if st.button("ğŸ“¦ íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ìƒì„±", type="primary"):
                try:
                    packing_items, summary = st.session_state.packing_generator.generate_packing_list()
                    
                    if not packing_items:
                        st.warning("íŒ¨í‚¹í•  ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ
                        st.success(f"âœ… íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ! (ì´ {len(packing_items)}ê°œ ìƒí’ˆ)")
                        
                        # ìš”ì•½ ì •ë³´
                        st.markdown("### ğŸ“‹ íŒ¨í‚¹ ìš”ì•½")
                        summary_cols = st.columns(5)
                        
                        with summary_cols[0]:
                            st.metric("ì´ ìƒí’ˆ ì¢…ë¥˜", summary.total_items)
                        with summary_cols[1]:
                            st.metric("ì´ ë¬´ê²Œ", f"{summary.total_weight:.1f} KG")
                        with summary_cols[2]:
                            st.metric("ì „ì²´ ì£¼ë¬¸ ê±´ìˆ˜", summary.total_orders)
                        with summary_cols[3]:
                            st.metric("ê³ ìœ  ë°°ì†¡ì§€", summary.unique_delivery_locations)
                        with summary_cols[4]:
                            st.metric("í•©ë°°ì†¡ ê±´", summary.combined_delivery_count)
                        
                        # íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ í…Œì´ë¸”
                        st.markdown("### ğŸ“¦ ìƒì„¸ íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸")
                        
                        # ê°„ì†Œí™”ëœ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                        packing_data = []
                        for item in packing_items:
                            row = {
                                'ìƒí’ˆëª…': item.product_name,
                            }
                            
                            # ìˆ˜ëŸ‰ í‘œì‹œ (ëª¨ë“  ìˆ˜ëŸ‰ ì •ìˆ˜ë¡œ í‘œì‹œ)
                            row['ìˆ˜ëŸ‰'] = int(item.quantity)
                            
                            # ì´ë¬´ê²Œ (ë‹­ë°œ ì œì™¸)
                            if item.category == 'ë‹­ë°œ':
                                row['ì´ë¬´ê²Œ(KG)'] = ''  # ë‹­ë°œì€ ë¬´ê²Œ í‘œì‹œ ì•ˆ í•¨
                            elif item.total_weight > 0:
                                row['ì´ë¬´ê²Œ(KG)'] = f"{item.total_weight:.1f}"
                            else:
                                row['ì´ë¬´ê²Œ(KG)'] = ''
                            
                            packing_data.append(row)
                        
                        packing_df = pd.DataFrame(packing_data)
                        st.dataframe(packing_df, use_container_width=True)
                        
                        # âŒ ë°°ì†¡ ë¶„ì„ ì„¹ì…˜ ì™„ì „ ì œê±° (UX ê°œì„ )
                        # ê¸°ì¡´ì˜ ë°°ì†¡ ë¶„ì„ í‘œì‹œ ì½”ë“œë¥¼ ëª¨ë‘ ì œê±°
                        
                        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        st.markdown("### ğŸ’¾ ë‹¤ìš´ë¡œë“œ")
                        
                        col1, col2 = st.columns(2)
                        
                        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ - íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ë§Œ (ë°°ì†¡ë¶„ì„ ì‹œíŠ¸ ì œê±°)
                        with col1:
                            output = io.BytesIO()
                            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                # íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ì‹œíŠ¸ë§Œ ìƒì„± (ë°°ì†¡ë¶„ì„ ì‹œíŠ¸ ì œê±°)
                                packing_df.to_excel(writer, sheet_name='íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸', index=False)
                            
                            output.seek(0)
                            
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            filename = f"íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸_{timestamp}.xlsx"
                            
                            st.download_button(
                                label="ğŸ“Š íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                                data=output.getvalue(),
                                file_name=filename,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        
                        # CSV ë‹¤ìš´ë¡œë“œ
                        with col2:
                            csv_data = packing_df.to_csv(index=False, encoding='utf-8-sig')
                            
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            filename = f"íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸_{timestamp}.csv"
                            
                            st.download_button(
                                label="ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ",
                                data=csv_data,
                                file_name=filename,
                                mime="text/csv"
                            )
                        
                except Exception as e:
                    st.error(f"íŒ¨í‚¹ë¦¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
    
    else:
        st.info("ğŸ‘† ë¨¼ì € ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()